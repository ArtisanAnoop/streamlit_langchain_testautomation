import re
import warnings

import streamlit as st
from dotenv import load_dotenv
from langchain_community.callbacks import get_openai_callback
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.llms.huggingface_hub import HuggingFaceHub

warnings.filterwarnings('ignore')


def init_page():
    # st.set_page_config(
    #     page_title="AI-powered API Test Script Generator - Anoop Korappath", page_icon=":rocket:", layout="centered",
    #     initial_sidebar_state="expanded"
    # )
    st.markdown("""
        <style>
            .header {
                font-family: Arial, sans-serif;
                color: #00325B;
                font-size: 24px;
                text-align: center;
                padding: 10px;
                background-color: #FF8C02;
                border: none;
            }
        </style>
        <div class="header">AI-Powered API Test Script Creation</div>
    """, unsafe_allow_html=True)
    st.markdown("""
        <div style="text-align: center;">Create api test scenarios from schema.</div>
        """, unsafe_allow_html=True)


def generate_test_scenarios_str(num_functional, num_security, num_usability, num_performance, num_visual,
                                num_accessibility):
    messages = []
    total_tests = num_functional + num_security + num_usability + num_performance + num_visual + num_accessibility

    if num_functional > 0:
        messages.append(f"You should create {num_functional} functional test scenarios")
    if num_security > 0:
        messages.append(f"You should create {num_security} security test scenarios")
    if num_usability > 0:
        messages.append(f"You should create {num_usability} usability test scenarios")
    if num_performance > 0:
        messages.append(f"You should create {num_performance} performance test scenarios")
    if num_visual > 0:
        messages.append(f"You should create {num_visual} visual test scenarios")
    if num_accessibility > 0:
        messages.append(f"You should create {num_accessibility} accessibility test scenarios")

    messages.append(f"Total number of test scenarios required is {total_tests}")
    return '\n'.join(f"{i + 1}) {message}" for i, message in enumerate(messages))


def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-4", "Gemini", "Mistral AI"))
    if model == "GPT-4":
        model_name = "gpt-4"
    elif model == "Gemini":
        model_name = "gemini-1.0-pro-latest"
    else:
        model_name = "mistralai/Mistral-7B-Instruct-v0.2"

    popup_text = """Temperature controls the randomness of text generated by a large language model.  A higher temperature leads to more creative and unexpected output, while a lower temperature produces more predictable and reliable text. [more info](https://www.iguazio.com/glossary/llm-temperature/)"""
    temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=1.0, value=0.0, step=0.01, help=popup_text)

    if model == "Gemini":
        return ChatGoogleGenerativeAI(model=model_name, temperature=temperature, convert_system_message_to_human=True)
    elif model == "GPT-4":
        return ChatOpenAI(temperature=temperature, model_name=model_name)
    elif model == "Mistral AI":
        return HuggingFaceHub(
            repo_id=model_name,
            model_kwargs={"temperature": 0.1, "max_tokens": 5000, "top_p": 0.2, "max_new_tokens": 6000,
                          "num_return_sequences": 1})


def get_answer(llm, messages):
    with get_openai_callback() as cb:
        # Check if llm is an instance of HuggingFaceHub
        if isinstance(llm, HuggingFaceHub):
            # Join the content of the messages into a single string
            prompt = ' '.join(message.content for message in messages)
            answer = llm(prompt)
            # Split the output at the last occurrence of the prompt
            _, generated_content = answer.rsplit(prompt, 1)
            return generated_content.strip(), cb.total_cost
        else:
            answer = llm(messages)
            return answer.content, cb.total_cost


def _fix_streamlit_space(text: str) -> str:
    """Fix streamlit issue where a newline needs 2 spaces before it.
    See https://github.com/streamlit/streamlit/issues/868
    """

    def _replacement(match: re.Match):
        # Check if the match is preceded by a space
        if match.group(0).startswith(" "):
            # If preceded by one space, add one more space
            return " \n"
        else:
            # If not preceded by any space, add two spaces
            return "  \n"

    return re.sub(r"( ?)\n", _replacement, text)


def on_click():
    st.session_state.schema = ""
    st.session_state.url = ""


def main():
    global template
    init_page()
    load_dotenv()
    sidebar = st.sidebar
    sidebar.title("Options")
    llm = select_model()

    sample_schema = {
        "$schema": "http://json-schema.org/draft-04/schema#",
        "title": "Person",
        "description": "A person",
        "type": "object",
        "properties": {
            "name": {
                "description": "A person's name",
                "type": "string"
            },
            "age": {
                "description": "A person's age",
                "type": "number",
                "minimum": 18,
                "maximum": 64
            }
        },
        "required": ["name", "age"]
    }

    help_text = _fix_streamlit_space(
        "\nJSON Schema is a grammar language for defining the structure, content, and (to some extent) semantics of JSON objects. It lets you specify metadata (data about data) about what an objectâ€™s properties mean and what values are valid for those properties.\n"
        + "\n\nExample:\n" + str(sample_schema))

    st.write("\n\n\n")
    st.write("\n\n\n")

    schema_input = st.text_area("Enter the api schema", height=200, value="",
                                help=help_text,
                                key="schema")
    url_input = st.text_input("Enter the url", value="",
                              key="url")

    tool_options = [
        "Java-Apache HTTPClient",
        "Java-RestAssured",
        "Karate",
        "Postman",
        "JMeter",
        "Curl"
    ]

    selected_tool = st.selectbox("Select your preferred tool/library:", tool_options)

    submit = st.button("Generate")
    reset = st.button("Reset", on_click=on_click)

    st.markdown("""
        <style>
             .stButton>button {
                background-color: #FF8C02;
                padding: 14px 20px;
                margin: 8px 0;
                border: none;
                cursor: pointer;
                width: 100%;
                opacity: 0.9;
                font-weight: bold;
                font-family: Arial, sans-serif;
                color: #00325B;
                font-size: 30px;
                text-align: center;
                background-color: #FF8C02;
            }

            .stButton>button:hover {
                opacity:1;
            }
        </style>
        """, unsafe_allow_html=True)

    main_prompt = create_prompt()

    initial_human_message = main_prompt + "\n\nHere is the actual schema and url that you have to work on \n\n" + "Schema is \n" + schema_input + "URL is " + url_input

    messages = [SystemMessage(
        content="You are a Software QA engineer expert in writing api test in " + selected_tool + "\n" + initial_human_message),
    ]

    if submit:
        messages.append(HumanMessage(content=_fix_streamlit_space(schema_input)))
        with st.spinner("Working...."):
            answer, cost = get_answer(llm, messages)
            messages.append(AIMessage(content=_fix_streamlit_space(answer)))
            sidebar.markdown(f"- Cost: ${cost:.5f}")

        for message in messages:
            if isinstance(message, AIMessage):
                with st.chat_message('assistant'):
                    st.markdown(_fix_streamlit_space(message.content), unsafe_allow_html=True)
            # elif isinstance(message, HumanMessage):
            #     with st.chat_message('user'):
            #         st.write(_fix_streamlit_space(message.content))
    if reset:
        messages = [SystemMessage(
            content="You are a Software QA engineer expert in writing api test in " + selected_tool + "\n"),
            HumanMessage(
                content=main_prompt + "\n\nHere is the actual schema and url that you have to work on \n\n" + "Schema is \n" + schema_input + "URL is " + url_input)
        ]
        st.empty()


def create_prompt():
    json_schema = """
      {
     "$schema": "https://json-schema.org/draft/2019-09/schema#",
     "$id": "http://my-paintings-api.com/schemas/painting-schema.json",
     "type": "object",
     "title": "Painting",
     "description": "Painting information",
     "additionalProperties": true,
     "required": ["name", "artist", "dimension", "description", "tags"],
     "properties": {
       "name": {
         "type": "string",
         "description": "Painting name"
       },
       "artist": {
         "type": "string",
         "maxLength": 50,
         "description": "Name of the artist"
       },
       "description": {
         "type": ["string", "null"],
         "description": "Painting description"
       },
       "dimension": { "$ref": "#/$defs/dimension" },
       "tags": {
         "type": "array",
         "items": { "$ref": "#/$defs/tag" }
       }
     },
     "$defs": {
       "tag": {
         "type": "string",
         "enum": ["oil", "watercolor", "digital", "famous"]
       },
       "dimension": {
         "type": "object",
         "title": "Painting dimension",
         "description": "Describes the dimension of a painting in cm",
         "additionalProperties": true,
         "required": ["width",  "height"],
         "properties": {
           "width": { "type": "number", "description": "Width of the product", "minimum": 1 },
           "height": { "type": "number", "description": "Height of the product", "minimum": 1 }
         }
       }
     }
    }
    """

    json_response = """{ "id": "132-323-233-23323", "status": "saved" }"""
    sample_output = """
    public class TestRestAssured {
      @Before
      public void setUp() {
        RestAssured.enableLoggingOfRequestAndResponseIfValidationFails();
        RestAssured.baseURI= "http://jsonplaceholder.typicode.com";
      }

      @Test
      public void exampleFailingTest() {
        String json = "{\n" +
            "  \"title\": \"foo\",\n" +
            "  \"body\": \"bar\",\n" +
            "  \"userId\": 1\n" +
            "}";
        given()
            .contentType("application/json; charset=UTF-8")
            .body(json)
            .post("/posts")
            .then()
            .body("userId", equalTo(2));
      }
    }
    """

    main_prompt = f"""
                    Task:  Utilize the provided JSON schema to generate comprehensive test cases for a REST API.

                    Directives:
                    1) Create scripts/tests based on the language provided by the system
                    2) Strive to generate the minimum number of test cases needed to cover all the scenarios
                    3) There should be test cases for 2xx series response code, 4xx series response codes and 5xx series response codes
                    4) Add comments as needed
                    5) Add assertions to all the tests
                    6) Please provide full code and not just place holders
                    7) Use logging also in the code wherever applicable
                    8) Don't include any explanations in your responses. Only code is needed.

                    Specific Requirements:

                    JSON Schema: Provide the JSON schema either as a file or an embedded JSON object.
                    REST API Endpoint Details: Specify the base URL of your REST API and the endpoints you want to test (e.g., "/users" for a POST request).
                    HTTP Methods: Indicate the supported HTTP methods (GET, POST, PUT, DELETE, etc.) for each endpoint.
                    Additional Considerations (Optional):
                    Authentication: If your API requires authentication, provide login test cases or instructions on how to obtain and use authentication tokens.
                    Test Data Sets: Supply specific sets of test data if needed for tailored scenarios.

                    Focus Areas:

                    Request Structure Validation: Verify that request payloads sent to the API adhere to the JSON schema (correct data types, required fields, format constraints).
                    Response Structure Validation: Ensure that API responses conform to the JSON schema.
                    Status Code Verification: Assert that the API returns expected HTTP status codes for different scenarios (e.g., success, errors).
                    Parameterization: Allow tests to be data-driven. Generate examples to cover the range of valid and invalid values specified in the schema.
                    Edge Case Testing: Include tests that target potential boundary conditions outlined in the schema.


                    Constraints:
                    Utilize the library or language the user selected: Employ the library for its convenient syntax and features.
                    Clear Readability: Produce well-formatted and commented test code, emphasizing maintainability and understanding.

                    Considerations:
                    Parameterized Tests: If applicable, allow for parameterized tests to cover multiple data variations efficiently.
                    Error Handling: Ensure proper handling and reporting of failed tests.
                    Data Generation: If needed, provide functionality to suggest or generate test data (valid and invalid) based on the schema and test instructions.

                    Example schema for a painting API is given below.
                    JSON request schema : 
                    {json_schema}

                    Expected Status Code: 200 
                    URL  :  "https://reqres.in/api/saveUsers". 
                    Expected Response Body: {json_response}

                    An example of a valid response using Java-RestAssured is given below

                    {sample_output}
                   """.strip()
    return main_prompt


if __name__ == '__main__':
    main()